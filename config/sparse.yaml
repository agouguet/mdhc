# Learning params
learning:
  total_timesteps: 50000000 #20000000
  n_steps: 1024
  learning_rate: 0.00005
  num_envs: 10
  speed_time: 1.0
  save_model_frequency: 5000000
  curriculum:
    mode: "steps"     # "steps" | "time" | "plateau"
    max_level: 3
    window_size: 10
    epsilon: 0.5
    patience: 5
    thresholds:
      - [0, 50000000, 0]
    level:
      - ["sparse", 1, 10]

    

# Logging
log:
  name: "frontal"
  log_dir: "./log_drl/"
  log_interval: 1
  throttle_duration: 0.5
  ros: true

# RL Algo
algo:
  name: "ppo"
  clip_range: 0.2
  batch_size: 256        
  n_epochs: 10            
  vf_coef: 0.5
  ent_coef: 0.005         
  learning_rate_schedule: "linear"
  seed: 42

# Policy network
policy:
  name: "mdhc"
  features_dim: 512
  pi_layers: [512, 256]
  vf_layers: [256, 128]
  activation_fn: "tanh"

# Environment observations
env:
  name: "hbsn"
  max_iteration: 20000
  steps_on_goal_required: 1
  max_time: 90
  normalize_reward: False #True
  normalize_observation: False

  action:
    discrete: false
    discrete_level_linear: 5
    discrete_level_angular: 5

  obs:
    goal: true
    goal_social: true
    goal_dist: false
    scan: true
    scan_dim: 720
    scan_history: 1
    scan_slice: 16
    scan_tile: 1
    scan_avg_pool: false #true
    scan_min_pool: true
    scan_norm: true #true
    robot_velocity: true
    human: true
    human_number: 10
    human_history: 1
    

  reward:
    constant: -0.00 #-0.01
    backward: -0.2
    goal_arrival: 100
    goal_stay_bonus: 10.0
    goal_waypoint: 5.0
    goal_radius: 0.2
    goal_dist_history_number: 10
    collision: -100
    scan: -1.5 #-0.2
    scan_penalty_threshold_factor: 2.0
    theta_angle: 0.2
    rotation: -0.1
    human: 10.0
    human_personal_distance: 1.0

  robot:
    robot_radius: 0.35
    min_linear_velocity: 0.0
    max_linear_velocity: 1.0
    min_angular_velocity: -2.0
    max_angular_velocity: 2.0

  ros:
    robot_odom: "/robot_odom"
    robot_pose: "/robot_pose"
    cnn_data: "/cnn_data"
    global_goal: "/global_goal"
    cmd_vel: "/smooth_cmd_vel"
    reset_service: "/unity/reset"
    play_service: "/unity/play"
